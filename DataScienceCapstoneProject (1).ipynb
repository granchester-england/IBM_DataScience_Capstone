{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Capstone project Data Science"}, {"metadata": {}, "cell_type": "markdown", "source": "This project notebook is setup for the capstone project of thethe Data Science course."}, {"metadata": {}, "cell_type": "code", "source": "print('Hello Capstone Project Course!')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nimport seaborn as sns\n%matplotlib inline", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import types\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_dbc21f765edb4af4abc41f7c6fee8f2d = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='9a3_kaHLtHd9jk7VEUcLg3Ux-bxWR3dXKU8vHv_Vkq7M',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_dbc21f765edb4af4abc41f7c6fee8f2d.get_object(Bucket='datasciencecapstone-donotdelete-pr-g2ahuzkxhirpn2',Key='Data-Collisions.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_raw= pd.read_csv(body)\ndf_raw['SEVERITYCODE'].size", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### How many attributes"}, {"metadata": {}, "cell_type": "code", "source": "df_raw.columns.size", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Empty items in 'ROADCOND'"}, {"metadata": {}, "cell_type": "code", "source": "df_raw.columns", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_raw[df_raw['ROADCOND'].isna()==True].shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Data pre-processing"}, {"metadata": {}, "cell_type": "code", "source": "df_raw.columns\ncols=['SEVERITYCODE','WEATHER','ROADCOND','LIGHTCOND','WEATHER','COLLISIONTYPE']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Label encoding\nhttps://pbpython.com/categorical-encoding.html"}, {"metadata": {}, "cell_type": "code", "source": "cleanup={'ROADCOND': {'Dry':0, 'Wet':1, 'Unknown':2,'Ice':3, 'Snow/Slush':4, 'Other':5, 'Standing Water':6, 'Sand/Mud/Dirt':7,'Oil':8}, 'LIGHTCOND':{'Daylight':0,'Dark - Street Lights On':1, 'Unknown': 2, 'Dusk':3, 'Dawn':4, 'Dark - No Street Lights':5, 'Dark - Street Lights Off':6, 'Other':7, 'Dark - Unknown Lighting': 8},'WEATHER':{'Clear':0,'Raining':1,'Overcast':2,'Unknown':3,'Snowing':4,'Other':5,'Fog/Smog/Smoke':6,'Sleet/Hail/Freezing Rain':7,'Blowing Sand/Dirt':8,'Severe Crosswind':9,'Partly Cloudy':10},'COLLISIONTYPE':{'Parked Car':0,'Angles':1,'Rear Ended':2,'Other':3,'Sideswipe':4,'Left Turn':5, 'Pedestrian':6,'Cycles':7,'Right Turn':8,'Head On':9}\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df=df_raw[cols]\ndf.replace(cleanup, inplace=True)\ndf.head(3)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_filt=df.dropna()\ndf_filt['SEVERITYCODE'].size", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Label balancing"}, {"metadata": {}, "cell_type": "code", "source": "df_maj=df_filt[df_filt['SEVERITYCODE']==1]\ndf_min=df_filt[df_filt['SEVERITYCODE']==2]\nprint([df_maj.SEVERITYCODE.size,df_min.SEVERITYCODE.size])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.utils import resample\ndf_maj_downsampled=resample(df_maj,replace=False,n_samples=df_min.SEVERITYCODE.size, random_state=123)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_ds=pd.concat([df_maj_downsampled,df_min])\ndf_ds.SEVERITYCODE.value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Initialisation"}, {"metadata": {}, "cell_type": "code", "source": "X=df_ds[['WEATHER','ROADCOND','LIGHTCOND','WEATHER','COLLISIONTYPE']]\ny=df_ds['SEVERITYCODE']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Normalize"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import preprocessing\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX[0:3]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Train-test split"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import jaccard_similarity_score, f1_score, accuracy_score, classification_report, confusion_matrix\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Train models"}, {"metadata": {}, "cell_type": "markdown", "source": "### KNN"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.neighbors import KNeighborsClassifier", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Nearest neighbour there is a pre-step to figure out how many clusters. As I fully want the test set as confirmation I split the training set up into test/train once more just for KNN. ONLY USED FOR CLUSTER NO. ESTIMATION!"}, {"metadata": {}, "cell_type": "code", "source": "X_train_KNN, X_test_KNN, y_train_KNN, y_test_KNN = train_test_split( X_train, y_train, test_size=0.2, random_state=4)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"\nKs = 30\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    # Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train_KNN,y_train_KNN)\n    yhat=neigh.predict(X_test_KNN)\n    mean_acc[n-1] = accuracy_score(y_test_KNN, yhat)\n    std_acc[n-1]=np.std(yhat==y_test_KNN)/np.sqrt(yhat.shape[0])\n    \nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- std'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Found that clusters=15 best!"}, {"metadata": {}, "cell_type": "code", "source": "neigh = KNeighborsClassifier(n_neighbors = 15).fit(X_train, y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Decision Tree"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.tree import DecisionTreeClassifier\npTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 7)\npTree.fit(X_train,y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Support vector machine"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Logistic regression"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\n\"\"\"\nX_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split( X_train, y_train, test_size=0.2, random_state=4)\n\nl=[1,3,6,9]\nmean_acc = np.zeros((len(l)-1))\nstd_acc = np.zeros((len(l)-1))\nConfustionMx = [];\nfor x in l:\n    print(x)\n    LR = LogisticRegression(C = x, solver='liblinear').fit(X_train_LR,y_train_LR)\n    yhat = LR.predict(X_test_LR)\n    yhat_prob = LR.predict_proba(X_test_LR)\n    print(\"Logistic Regression evaluation F1-score: \", f1_score(y_test_LR, yhat, average='weighted') )\n    mean_acc[n-1] = accuracy_score(y_test_LR, yhat)\n    std_acc[n-1]=np.std(yhat==y_test_LR)/np.sqrt(yhat.shape[0])\n\nplt.plot(range(1,len(l)),mean_acc,'g')\nplt.fill_between(range(1,len(l)),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- std'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()\n\"\"\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The regularization parameter C = 6 appears to fit best."}, {"metadata": {}, "cell_type": "code", "source": "LR = LogisticRegression(C = 6, solver='liblinear').fit(X_train,y_train)\nLR", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Model evaluation"}, {"metadata": {}, "cell_type": "markdown", "source": "### KNN"}, {"metadata": {}, "cell_type": "code", "source": "yhat=neigh.predict(X_test)\nprint(\"KNN's evaluation F1-score: \", f1_score(y_test, yhat, average='weighted') )\nprint(\"KNN's evaluation Jaccard-score: \",jaccard_similarity_score(y_test, yhat) )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Decision tree"}, {"metadata": {}, "cell_type": "code", "source": "yhat = pTree.predict(X_test)\nprint(\"DecisionTrees's F1-score: \", f1_score(y_test, yhat, average='weighted')  )\nprint(\"DecisionTrees's  evaluation Jaccard-score: \", jaccard_similarity_score(y_test, yhat) )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Logistic regression"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.metrics import log_loss\nyhat = LR.predict(X_test)\nyhat_prob = LR.predict_proba(X_test)\nprint(\"Logistic Regression evaluation F1-score: \", f1_score(y_test, yhat, average='weighted') )\nprint(\"Logistic Regression evaluation Jaccard-score: \", jaccard_similarity_score(y_test, yhat) )\nprint(\"Logistic Regression evaluation Logloss-score: \", log_loss(y_test, yhat_prob) )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### SVM"}, {"metadata": {}, "cell_type": "code", "source": "yhat = clf.predict(X_test)\nprint(\"SVM evaluation F1-score: \", f1_score(y_test, yhat, average='weighted')  )\nprint(\"SVM evaluation Jaccard-score: \", jaccard_similarity_score(y_test, yhat) )", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The end"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}